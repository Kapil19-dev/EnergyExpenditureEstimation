{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to run without requiring jupyter notebook, see the main.py file\n",
    "\n",
    "## Load modules\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import os\n",
    "import dataHelp as dh\n",
    "import paramSearchHelper as psh\n",
    "cwd = os.getcwd() # current working directory\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(cwd))\n",
    "import utils\n",
    "import NNModel as NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set \"param_file\" to the name of a .json file in the settings folder \n",
    "param_file = \"nn_assisted_conditions_subj\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the params file\n",
    "param_dir = cwd+\"/\"+\"settings\" # change directory to settings\n",
    "if (param_file == \"-f\"):\n",
    "    print(\"No input .json file given\")\n",
    "else:\n",
    "    param_path = param_dir+\"/\"+param_file+\".json\"\n",
    "    params = utils.Params(param_path) # load setting file\n",
    "\n",
    "# convert params strings bools to booleans\n",
    "def str2bool(v):\n",
    "  return v.lower() in (\"true\")\n",
    "\n",
    "# Model type\n",
    "model_type = params.model_type\n",
    "sim_type = params.sim_type # hps:hyperparam search, sm:single model train, subj: test set of 10 subjects\n",
    "batch_size = params.batch_size #128 # 1 to not batch\n",
    "sequence_length = params.sequence_length # this should be however many \"bins\" we use\n",
    "num_epochs = params.num_epochs # total number of epochs to iterate through\n",
    "\n",
    "# Load data\n",
    "data_folder = params.data_folder\n",
    "data_type = params.data_type # subjects, conditions, or data\n",
    "features = params.features\n",
    "signals = params.signals\n",
    "y_ind = params.y_ind # which metabolic predictor to use\n",
    "norm = str2bool(params.norm) # whether to normalize data\n",
    "seed = params.seed\n",
    "if data_folder[:8] == \"assisted\": # assisted dataset\n",
    "    seed_list = [2,10,3,5,25,1,9,7] # first random seed numbers to get the subjects in order\n",
    "else: # incline-load dataset\n",
    "    seed_list = [41,17,13,5,7,1,40,32,2,10,3,12,9]\n",
    "\n",
    "train_size = params.train_size\n",
    "\n",
    "if (data_type == \"subjects\") and (sim_type == \"hps\" or sim_type == \"sm\"):\n",
    "    if data_folder[:8] == \"assisted\":\n",
    "        test_size = 2\n",
    "    else:\n",
    "        test_size = 3\n",
    "elif (data_type == \"subjects\" or data_type[0:8] == \"subjcond\"):\n",
    "    test_size = 1\n",
    "else:\n",
    "    test_size = 0.1\n",
    "\n",
    "if params.test_size != -1: # not using default\n",
    "    test_size = params.test_size\n",
    "\n",
    "# Single model settings\n",
    "learning_rate = params.learning_rate\n",
    "print_interval = params.print_interval # number of prints\n",
    "plot_interval = params.plot_interval # data points in the plots\n",
    "num_hid_layers = params.num_hid_layers\n",
    "size_hid_layers = params.size_hid_layers\n",
    "printing = str2bool(params.printing) # True prints the losses and train/test errors as the network is trained\n",
    "plotting = str2bool(params.plotting)\n",
    "num_sims = params.num_sims # number of simulations run for the hyperparamSearch\n",
    "beta = params.beta\n",
    "k_p = params.k_p\n",
    "reg_type = params.reg_type\n",
    "saving = str2bool(params.saving)\n",
    "log_dir = data_type+\"_\"+ data_folder\n",
    "parallel = str2bool(params.parallel)\n",
    "cores = params.cores # number of cores to run parallel trials\n",
    "decay = str2bool(params.decay)\n",
    "batch_norm = str2bool(params.batch_norm)\n",
    "\n",
    "lr_rng = [params.lr_min, params.lr_max]\n",
    "num_hid_layers_rng = [params.num_hl_min, params.num_hl_max]\n",
    "size_hid_layers_rng = [params.sz_hl_min, params.sz_hl_max]\n",
    "beta_rng = [params.beta_min, params.beta_max]\n",
    "k_p_rng = [params.k_p_min, params.k_p_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test conditions:  [49, 34, 7, 43, 22, 15, 40]\n",
      "Test conditions:  [0, 8, 29, 28, 64, 15, 9]\n",
      "Test conditions:  [41, 19, 21, 0, 56, 3, 24]\n"
     ]
    }
   ],
   "source": [
    "# Loading data and running the models/search/subjects\n",
    "num_runs = len(seed_list) if sim_type == \"subj\" else 1\n",
    "test_results = []\n",
    "label_results = []\n",
    "train_errs = []\n",
    "train_r2 = []\n",
    "train_rmse = []\n",
    "train_mae = []\n",
    "test_errs = []\n",
    "test_rmse = []\n",
    "test_mae = []\n",
    "\n",
    "for i in range(num_runs): # loop through subjects if necessary\n",
    "    if sim_type == \"subj\":\n",
    "        seed = seed_list[i]\n",
    "        printing = False\n",
    "        plotting = False\n",
    "        saving = False\n",
    "        #data_type = \"subjects\"\n",
    "        \n",
    "    # Load data\n",
    "    x_train, Y_train, x_dev, Y_dev, x_test, Y_test = dh.loadData(data_type, cwd, seed, y_ind, train_size, test_size, features, norm, data_folder, sequence_length, signals)\n",
    "\n",
    "    if batch_size != 1: # need axis swap and/or batching\n",
    "        X_train = x_train\n",
    "        X_dev = x_dev\n",
    "        X_test = x_test\n",
    "        X_train, Y_train = dh.batch_nonseq(X_train, Y_train, batch_size)\n",
    "    else:\n",
    "        X_train = x_train\n",
    "        X_dev = x_dev\n",
    "        X_test = x_test\n",
    "    if (sim_type == \"sm\") or (sim_type == \"subj\"):\n",
    "        if model_type == \"NN\":\n",
    "            results = NN.model(cwd, X_train, Y_train, X_dev, Y_dev, X_test, Y_test, learning_rate, beta, k_p, reg_type, num_epochs, num_hid_layers, size_hid_layers, batch_size, log_dir, decay, batch_norm, saving, printing, plotting, print_interval, plot_interval, parallel, queue=0)\n",
    "    elif sim_type == \"hps\":\n",
    "        results = psh.hyperparamSearch(param_file, model_type, cwd, X_train, Y_train, X_dev, Y_dev, X_test, Y_test, lr_rng, num_hid_layers_rng, beta_rng, k_p_rng, reg_type, size_hid_layers_rng, num_sims, num_epochs, batch_size, log_dir, decay, batch_size, batch_norm, parallel, cores)\n",
    "\n",
    "    if (sim_type == \"subj\"):\n",
    "        # new output from NN model: results = train_err, train_r2, train_rmse, train_mae, dev_err, test_err, test_rmse, test_mae, min_dev, min_test, min_epoch, test_avg, Y_avg\n",
    "        test_results.append(results[-2])\n",
    "        label_results.append(results[-1])\n",
    "        train_errs.append(results[0])\n",
    "        train_r2.append(results[1])\n",
    "        train_rmse.append(results[2])\n",
    "        train_mae.append(results[3])\n",
    "        test_errs.append(results[5])\n",
    "        test_rmse.append(results[6])\n",
    "        test_mae.append(results[7])\n",
    "        \n",
    "if (sim_type == \"subj\"):\n",
    "    log_name = \"Subj_run_\"+str(model_type)+\"\"+str(learning_rate)+\"\"+str(num_epochs)+\"\"+str(num_hid_layers)+\"\"+str(size_hid_layers)\n",
    "    try: # if no log folder exists, create it\n",
    "        os.mkdir(cwd+\"/\"+log_dir)\n",
    "    except:\n",
    "        print(\"directory exists\")\n",
    "    utils.set_logger(os.path.join(cwd+\"/\"+log_dir,log_name+'.log'))\n",
    "    utils.logging.info(\"START OF NEW SUBJECT RUN\")\n",
    "    utils.logging.info(\"Avg Train Error: %f\", np.mean(train_errs))\n",
    "    utils.logging.info(\"Avg Test Error: %f\", np.mean(test_errs))\n",
    "    utils.logging.info(\"Std Test Error: %f\", np.std(test_errs))\n",
    "    utils.logging.info(\"Subject Test Errors: \"+str(test_errs))\n",
    "    utils.logging.info(\"Avg Train R^2: %f\", np.mean(train_r2))\n",
    "    utils.logging.info(\"Avg Test RMSE: %f\", np.mean(test_rmse))\n",
    "    utils.logging.info(\"Avg Test MAE: %f\", np.mean(test_mae))\n",
    "    utils.logging.info(\"PREDICTED THEN ACTUAL RESULTS BELOW\")\n",
    "    utils.logging.info(test_results)\n",
    "    utils.logging.info(label_results)\n",
    "\n",
    "    dh.confusionMat(test_results, label_results, True, cwd+\"/\"+log_dir, log_name)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
