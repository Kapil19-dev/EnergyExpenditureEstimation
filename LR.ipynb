{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load modules\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import dataHelp as dh\n",
    "cwd = os.getcwd() # current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitSignals(signals, bin_size, data_labels, features, forces):\n",
    "    if signals == \"EMG\":\n",
    "        start = forces*bin_size\n",
    "        stop = features*bin_size-1\n",
    "        data_labels = data_labels[forces:]\n",
    "    elif signals == \"forces\":\n",
    "        start = 0\n",
    "        stop = forces*bin_size-1\n",
    "        data_labels = data_labels[0:forces]\n",
    "    elif signals == \"all\":\n",
    "        start = 0\n",
    "        stop = features*bin_size-1\n",
    "    return start, stop, data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test conditions:  [28, 122, 92, 88, 105, 86, 84, 131, 109, 26, 151, 89, 65, 80, 140]\n",
      "Test conditions:  [131, 10, 41, 17, 129, 7, 39, 68, 31, 22, 57, 150, 134, 143, 111]\n",
      "Test conditions:  [11, 24, 1, 148, 139, 2, 52, 75, 73, 154, 126, 98, 16, 74, 82]\n",
      "Test conditions:  [86, 30, 65, 44, 27, 80, 113, 143, 7, 112, 8, 73, 144, 118, 99]\n",
      "Test conditions:  [135, 127, 68, 136, 42, 110, 89, 72, 23, 142, 92, 103, 151, 67, 25]\n",
      "Test conditions:  [50, 139, 101, 20, 25, 134, 71, 129, 144, 79, 133, 137, 72, 140, 37]\n",
      "Test conditions:  [14, 8, 145, 49, 73, 91, 55, 74, 19, 114, 71, 12, 50, 7, 70]\n",
      "Test conditions:  [35, 65, 150, 139, 4, 9, 3, 89, 71, 147, 88, 124, 54, 133, 43]\n",
      "Test conditions:  [37, 116, 124, 31, 63, 47, 151, 95, 7, 104, 75, 43, 22, 72, 15]\n",
      "Test conditions:  [139, 100, 16, 115, 40, 0, 73, 8, 151, 123, 113, 64, 15, 125, 9]\n",
      "Test conditions:  [2, 66, 81, 26, 142, 93, 119, 138, 107, 147, 21, 0, 131, 152, 106]\n",
      "Test conditions:  [13, 104, 117, 128, 74, 118, 141, 133, 49, 22, 76, 3, 130, 134, 75]\n",
      "Test conditions:  [124, 62, 128, 91, 117, 40, 59, 22, 65, 125, 150, 56, 155, 92, 126]\n",
      "Train error percent:  4.1422049632755975\n",
      "Test error percent:  6.717584105149345\n",
      "Test MAE:  31.967438767074288\n",
      "Test RMSE:  42.5021731644123\n",
      "R2 for the train sets:  0.9762960672040987\n"
     ]
    }
   ],
   "source": [
    "##### Load data\n",
    "folder_name= \"incline-load_conditions_30bins\" # dataset name here, use conditions for conditions/subjcond simulations\n",
    "data_type = \"conditions\" # subjects, conditions, or subjcond\n",
    "subject_test = True # set true to iteratively test on all subjects\n",
    "signals = \"all\" # all, EMG, or forces\n",
    "dataset = \"exo\"\n",
    "\n",
    "y_ind = 0 # which metabolic predictor to use, 0 is direct measured metabolic\n",
    "norm = True # whether to normalize data\n",
    "seed = 1 # to keep consistent results\n",
    "train_size = 0.8 # percent of data for training set\n",
    "conds_holdout = 2 # number of conditions to holdout and test for subjcond\n",
    "\n",
    "\n",
    "if folder_name[0:8] == \"assisted\":\n",
    "    dataset = \"exo\"\n",
    "    num_conds = 9\n",
    "    features = 22\n",
    "    forces = 6\n",
    "    seed_list = [2,10,3,5,25,1,9,7]\n",
    "    data_labels = np.array([\"Fx_R\", \"Fy_R\", \"Fz_R\", \"Fx_L\", \"Fy_L\", \"Fz_L\", \n",
    "               \"MGAS_R\", \"LGAS_R\", \"MSOL_R\", \"LSOL_R\", \"TA_R\", \"VASM_R\", \"RF_R\", \"BF_R\",\n",
    "               \"MGAS_L\", \"LGAS_L\", \"MSOL_L\", \"LSOL_L\", \"TA_L\", \"VASM_L\", \"RF_L\", \"BF_L\"])\n",
    "\n",
    "elif folder_name[0:12] == \"incline-load\":\n",
    "    dataset == \"incline_load\"\n",
    "    num_conds = 12\n",
    "    features = 14\n",
    "    forces = 6\n",
    "    seed_list = [41,17,13,5,7,1,40,32,2,10,3,12,9]\n",
    "    data_labels = np.array([\"Fx1\", \"Fy1\", \"Fz1\", \"Fx2\", \"Fy2\", \"Fz2\",\n",
    "                            \"SOL\", \"GAS\", \"TA\", \"MH\", \"BF\", \"VM\", \"VL\", \"RF\"])\n",
    "\n",
    "\n",
    "if data_type == \"subjects\" or data_type == \"conditions\" or data_type[0:8] == \"subjcond\":\n",
    "    if subject_test:\n",
    "        test_size = 1\n",
    "        runs = len(seed_list)\n",
    "    else:\n",
    "        test_size = 3\n",
    "        runs = 1\n",
    "else:\n",
    "    test_size = 0.1\n",
    "    runs = 1\n",
    "    \n",
    "if data_type == \"subjcond\":\n",
    "    data_type = data_type + \" \" + str(conds_holdout)\n",
    "\n",
    "training_err = []\n",
    "deving_err = []\n",
    "testing_err = []\n",
    "\n",
    "R2s = []\n",
    "test_rmses = []\n",
    "test_maes = []\n",
    "\n",
    "pred_out = [] # for confusion mat\n",
    "actual_out = [] # for confusion mat\n",
    "\n",
    "for i in range(runs): # number of times iteratively testing for averaged results\n",
    "    \n",
    "    if subject_test:\n",
    "        seed = seed_list[i]\n",
    "    X_train, Y_train, X_dev, Y_dev, X_test, Y_test = dh.loadData(data_type, cwd, seed, y_ind, train_size, test_size, features, norm, folder_name, None, signals)\n",
    "\n",
    "    # Selecting which signals to include:\n",
    "    bin_size = int(X_train.shape[1]/features) # check to compute bin size is 30\n",
    "    start, stop, data_labels = splitSignals(signals, bin_size, data_labels, features, forces)\n",
    "               \n",
    "    signal_rng = np.linspace(start,stop,stop-start+1).astype(int)\n",
    "    X_train = X_train[:,signal_rng]\n",
    "    X_dev = X_dev[:,signal_rng]\n",
    "    X_test = X_test[:,signal_rng]\n",
    "    \n",
    "    lm = LinearRegression() # define linear model\n",
    "    lm.fit(X_train,Y_train) # train on the data\n",
    "    \n",
    "    train_pred = lm.predict(X_train)\n",
    "    test_pred = lm.predict(X_test)\n",
    "    dev_pred = lm.predict(X_dev)\n",
    "    \n",
    "    R2 = r2_score(Y_train, train_pred) # compute R squared on training data\n",
    "    \n",
    "    test_mae = np.mean(abs(test_pred - Y_test))\n",
    "    test_rmse = np.sqrt(mean_squared_error(Y_test, test_pred))\n",
    "\n",
    "    train_err = np.mean(abs((train_pred - Y_train)/Y_train)) # absolute error\n",
    "    dev_err = np.mean(abs((dev_pred - Y_dev)/Y_dev))\n",
    "    test_err = np.mean(abs((test_pred - Y_test)/Y_test))\n",
    "    training_err.append(train_err)\n",
    "    testing_err.append(test_err)\n",
    "    deving_err.append(dev_err)\n",
    "    R2s.append(R2)\n",
    "    test_maes.append(test_mae)\n",
    "    test_rmses.append(test_rmse)\n",
    "    pred_avg, actual_avg = dh.avgSubjectCond(test_pred,Y_test)\n",
    "    pred_out.append(pred_avg)\n",
    "    actual_out.append(actual_avg)\n",
    "\n",
    "print(\"Train error percent: \",np.mean(training_err)*100)\n",
    "#print(\"Dev error percent: \",np.mean(deving_err)*100)\n",
    "print(\"Test error percent: \",np.mean(testing_err)*100)\n",
    "print(\"Test MAE: \",np.mean(test_maes))\n",
    "print(\"Test RMSE: \",np.mean(test_rmses))\n",
    "print(\"R2 for the train sets: \",np.mean(R2s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4195, 420)\n",
      "Fz2 bin 10\n",
      "Fz1 bin 26\n",
      "Fz1 bin 30\n",
      "MH bin 18\n",
      "Fz2 bin 11\n",
      "GAS bin 22\n",
      "GAS bin 23\n",
      "Fz1 bin 23\n",
      "MH bin 19\n",
      "Fz2 bin 12\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "# Analayzing coefficients for linear model\n",
    "coef_print = 10 # how many coef to print out\n",
    "coef = lm.coef_ # coefficients for trained model\n",
    "coef_abs = abs(coef)\n",
    "coef_order = np.argsort(-coef_abs) # reverse order --> get largest weighted predictors first\n",
    "for i in range(coef_print):\n",
    "    feature = coef_order[i]//(bin_size) \n",
    "    bin_num = coef_order[i]%bin_size + 1\n",
    "    print(data_labels[feature] + ' bin ' + str(bin_num))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
